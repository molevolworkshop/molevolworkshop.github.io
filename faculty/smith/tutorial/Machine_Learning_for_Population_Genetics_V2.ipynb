{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c9f8d1c",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Author: Megan L Smith\n",
    "\n",
    "Date: May 4, 2024\n",
    "\n",
    "Purpose: Woodshole MOLE Course\n",
    "\n",
    "This jupyter notebook will illustrate an application of machine learning in population genetics. Specifically, we will simulate data under two simple demographic models using msprime. Then, we will calculate Site Frequency Spectra (SFS) from these data, and store them as numpy matrices. We will use these matrices to train a convolutional neural network (CNN) using tensorflow and keras. Finally, we will generate an independent test dataset and test the classifier. This is a simple example that does not require machine learning, but it should illustrate the basic principles of using machine learning in python to analyze genomic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a5236c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-06 20:37:31.828382: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Import python packages\n",
    "# python version: 3.10.8\n",
    "import msprime # version 1.2.0\n",
    "import numpy as np # version 1.23.5\n",
    "from scipy.spatial.distance import euclidean # version 1.9.3\n",
    "import random\n",
    "\n",
    "# sklearn imports version 1.2.0\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import confusion_matrix, accuracy_score \n",
    "\n",
    "# tensorflow imports version 2.10.0\n",
    "from tensorflow.keras import layers, optimizers, models \n",
    "\n",
    "# keras imports version 2.10.0\n",
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e216fd78",
   "metadata": {},
   "source": [
    "# Simulating genetic data in msprime\n",
    "\n",
    "There are many simulators we could use to simulate data, and different problems require different simulators. For example, when we want to simulate selection, SLiM (Haller and Messer, 2022) may be a good choice. In this simple example, we will use msprime (Baumdicker et al., 2022). msprime integrates well into python pipelines, since it is a python package. It is also used in stdpopsim, a library for standardized population genetic simulations for many species (Adrion et al., 2020). We will keep it simple for the point of illustration and simulate data under two models: a divergence-only model and a divergence-with-gene-flow model. Our question is: do these two sister species have a history of gene flow?\n",
    "\n",
    "<img src=\"Models-01.png\" width=\"500\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed5e4e1",
   "metadata": {},
   "source": [
    "## Specify demographic models\n",
    "\n",
    "Below, we specify our models. We could make these models much more complex. See the msprime documentation for more examples and possibilities: https://tskit.dev/msprime/docs/stable/demography.html. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54407fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our models in msprime\n",
    "\n",
    "def divergence(tdiv, ne_anc, ne_1, ne_2):  \n",
    "    \"\"\"This function defines a divergence-only model. \n",
    "        It takes as input several parameters:\n",
    "        tdiv (divergence time in generations)\n",
    "        ne_anc (the effective population size of the ancestral population)\n",
    "        ne_1 (the effective population size of population 1)\n",
    "        ne_2 (the effective population size of population 2)\"\"\"\n",
    "\n",
    "     # set up msprime model\n",
    "    demography = msprime.Demography()\n",
    "    demography.add_population(name=\"A\", initial_size = ne_1) # population 1\n",
    "    demography.add_population(name=\"B\", initial_size = ne_2) # population 2\n",
    "    demography.add_population(name=\"C\", initial_size = ne_anc) # ancestral population\n",
    "    demography.add_population_split(time=tdiv, derived=[\"A\", \"B\"], ancestral=\"C\") # divergence\n",
    "    return(demography)\n",
    "\n",
    "def geneflow(tdiv, migrate, ne_anc, ne_1, ne_2): # UPDATED\n",
    "    \"\"\"This function defines a secondary contact model. \n",
    "        It takes as input several parameters:\n",
    "        tdiv (divergence time in generations)\n",
    "        migrate (the rate of migration between populations)\n",
    "        ne_anc (the effective population size of the ancestral population)\n",
    "        ne_1 (the effective population size of population 1)\n",
    "        ne_2 (the effective population size of population 2)\"\"\"\n",
    "\n",
    "     # set up msprime model\n",
    "    demography = msprime.Demography()\n",
    "    demography.add_population(name=\"A\", initial_size = ne_1) # population 1\n",
    "    demography.add_population(name=\"B\", initial_size = ne_2) # population 2\n",
    "    demography.add_population(name=\"C\", initial_size = ne_anc) # ancestral population\n",
    "    demography.set_symmetric_migration_rate(populations=[\"A\", \"B\"], rate=migrate) # start migration\n",
    "    demography.add_symmetric_migration_rate_change(time=tdiv//2, populations=[\"A\", \"B\"], rate=0) # set migration rate to zero\n",
    "    demography.add_population_split(time=tdiv, derived=[\"A\", \"B\"], ancestral=\"C\") # divergence (migration stops)\n",
    "    return(demography)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f39d2c",
   "metadata": {},
   "source": [
    "## Specify priors and other values needed for simulations\n",
    "\n",
    "We will specify priors for parameters to use when generating training data. We also need to define a mutation rate. We could also draw this value from a prior distribution, but for the sake of simplicity, we will set Î¼ to a fixed value here. For this example (primarily for the sake of time) we assume there is no recombination within loci. Additionally, we need to specify the length of loci to simulate, the number of loci to simulate per replicate, the number of replicates to simulate per model, the number of SNPs to keep, and the number of individuals to sample per population. For this particular architecture, we assume equal numbers of samples from each population, but this is easily relaxed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7125612",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdiv_prior=[50000, 500000] # prior on divergence time\n",
    "ne_prior=[10000, 100000] # prior on ne\n",
    "migrate_prior=[1e-6,1e-4] # prior on migration rate\n",
    "mu = 1e-7 # mutation rate\n",
    "rec_rate = 1e-8\n",
    "seq_len = 100_000 # sequence length\n",
    "replicates = 100 # nubmer of replicates to simulate per model (there are 5000 per model in the dataset we will load.)\n",
    "sample_size = 10 # number of individuals to sample per extant population\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e51ec36",
   "metadata": {},
   "source": [
    "## Simulate data\n",
    "\n",
    "Now, we are ready to simulate data under our models. We will summarize our data using the Site Frequency Spectrum (SFS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "609c6756",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_data(tdiv_prior, ne_prior, sample_size, seq_len, mu, rec_rate, replicates):\n",
    "\n",
    "    # lists for storing matrices, responses\n",
    "    all_sfs = []\n",
    "    all_responses = []\n",
    "\n",
    "    \n",
    "    for model in ['divergence', 'geneflow']:\n",
    "        \n",
    "        for i in range(replicates):\n",
    "\n",
    "            # draw parameters from priors\n",
    "            this_tdiv = random.randint(tdiv_prior[0], tdiv_prior[1])\n",
    "            this_ne_anc = random.randint(ne_prior[0], ne_prior[1])\n",
    "            this_ne_1 = random.randint(ne_prior[0], ne_prior[1])\n",
    "            this_ne_2 = random.randint(ne_prior[0], ne_prior[1])\n",
    "            if model == \"geneflow\":\n",
    "                this_migrate = np.random.uniform(low=migrate_prior[0], high=migrate_prior[1])\n",
    "               \n",
    "            # get our demography (using the function defined above)  \n",
    "            if model == \"divergence\":\n",
    "                demography = divergence(tdiv=this_tdiv, ne_anc=this_ne_anc, ne_1=this_ne_1, ne_2=this_ne_2)\n",
    "            elif model == \"geneflow\":\n",
    "                demography = geneflow(tdiv=this_tdiv, migrate=this_migrate, ne_anc=this_ne_anc, \n",
    "                                    ne_1=this_ne_1, ne_2=this_ne_2)\n",
    "\n",
    "            # simulate tree sequences\n",
    "            ts = msprime.sim_ancestry(samples={\"A\": sample_size, \"B\": sample_size}, \n",
    "                            demography = demography, sequence_length=seq_len, recombination_rate = rec_rate)\n",
    "    \n",
    "            # simulate mutations\n",
    "            mts = msprime.sim_mutations(ts, rate=mu)\n",
    "\n",
    "            # SFS\n",
    "            sfs = mts.allele_frequency_spectrum(sample_sets=[mts.samples(0), mts.samples(1)], span_normalise=False, polarised=True)\n",
    "    \n",
    "            # get responses\n",
    "            if model == 'divergence':\n",
    "                response = 0\n",
    "            elif model == 'geneflow':\n",
    "                response = 1\n",
    "    \n",
    "            # append to lists\n",
    "            all_sfs.append(sfs)\n",
    "            all_responses.append(response)\n",
    "    \n",
    "    # convert lists to numpy arrays\n",
    "    all_sfs = np.stack(all_sfs, axis=0)\n",
    "    all_sfs = np.expand_dims(all_sfs, axis=-1)\n",
    "    all_responses = np.stack(all_responses)\n",
    "    \n",
    "    \n",
    "    return(all_sfs, all_responses)\n",
    "\n",
    "\n",
    "simulated_sfs, simulated_responses = simulate_data(tdiv_prior, ne_prior, sample_size, seq_len, mu, rec_rate, replicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2116d0be",
   "metadata": {},
   "source": [
    "# Save or Load\n",
    "To save some time, we will load a numpy array with more simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9e07614",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_sfs = np.load(\"simulated_sfs.npy\")\n",
    "simulated_responses = np.load(\"simulated_responses.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1badee2c",
   "metadata": {},
   "source": [
    "# Train a Machine Learning classifier!\n",
    "\n",
    "Now, we have data we can use to train our classifier. We need to build and train our classifier!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc8b494",
   "metadata": {},
   "source": [
    "## Build the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43760eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 21, 21, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 19, 19, 10)        100       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 9, 9, 10)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 7, 7, 10)          910       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 3, 3, 10)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 90)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 50)                4550      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 20)                1020      \n",
      "                                                                 \n",
      " final (Dense)               (None, 2)                 42        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,622\n",
      "Trainable params: 6,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-06 20:37:47.499125: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# create our layers\n",
    "conv1 = layers.Conv2D(10, (3, 3), activation='relu', input_shape=simulated_sfs.shape[1:])\n",
    "pool1 = layers.MaxPooling2D((2, 2))\n",
    "conv2 = layers.Conv2D(10, (3, 3), activation='relu')\n",
    "pool2 = layers.MaxPooling2D((2, 2))\n",
    "flatten = layers.Flatten(name=\"flatten\")\n",
    "dense50 = layers.Dense(50, activation='relu')\n",
    "dense20 = layers.Dense(20, activation='relu')\n",
    "densefinal = layers.Dense(2, activation='softmax', name=\"final\")\n",
    "\n",
    "# specify input\n",
    "x = layers.Input(shape=simulated_sfs.shape[1:])\n",
    "\n",
    "# build our model\n",
    "x1 = conv1(x)\n",
    "x1 = pool1(x1)\n",
    "x1 = conv2(x1)\n",
    "x1 = pool2(x1)\n",
    "x1 = flatten(x1)\n",
    "x1 = dense50(x1)\n",
    "x1 = dense20(x1)\n",
    "outputs = densefinal(x1)\n",
    "\n",
    "# compile the model\n",
    "model = models.Model(inputs=x, outputs=outputs)    \n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=0.00001), loss=\"categorical_crossentropy\", metrics='accuracy')\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f74d8b",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fd5826b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 2.3508 - accuracy: 0.4900 - val_loss: 1.2233 - val_accuracy: 0.5400\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.7773 - accuracy: 0.6602 - val_loss: 0.4583 - val_accuracy: 0.7987\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3491 - accuracy: 0.8597 - val_loss: 0.2420 - val_accuracy: 0.9137\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2065 - accuracy: 0.9295 - val_loss: 0.1610 - val_accuracy: 0.9525\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.1462 - accuracy: 0.9525 - val_loss: 0.1244 - val_accuracy: 0.9600\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.1154 - accuracy: 0.9635 - val_loss: 0.1043 - val_accuracy: 0.9675\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.0971 - accuracy: 0.9690 - val_loss: 0.0904 - val_accuracy: 0.9712\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.0853 - accuracy: 0.9730 - val_loss: 0.0808 - val_accuracy: 0.9750\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.0774 - accuracy: 0.9738 - val_loss: 0.0734 - val_accuracy: 0.9775\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.0716 - accuracy: 0.9763 - val_loss: 0.0677 - val_accuracy: 0.9775\n"
     ]
    }
   ],
   "source": [
    "# divide data into training, test, and validation\n",
    "train_features, test_val_features, train_labels, test_val_labels = train_test_split(simulated_sfs, simulated_responses, test_size = 0.4)\n",
    "test_features, val_features, test_labels, val_labels = train_test_split(test_val_features, test_val_labels, test_size = 0.2)\n",
    "\n",
    "# convert labels to categorical \n",
    "train_labels_cat = to_categorical(train_labels, num_classes=2)\n",
    "test_labels_cat = to_categorical(test_labels, num_classes=2)\n",
    "val_labels_cat = to_categorical(val_labels, num_classes=2)\n",
    "\n",
    "# fit our model\n",
    "history = model.fit(train_features, train_labels_cat, epochs=10, \n",
    "                        validation_data=(val_features, val_labels_cat), batch_size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f6d3b9",
   "metadata": {},
   "source": [
    "## Test the model\n",
    "\n",
    "It is important to test the model on an indpendent dataset. We did not use our test data for validation (which would be important if we adjusted model parameters to improve performance), or for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aff15bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 2ms/step\n",
      "[[1593   29]\n",
      " [  52 1526]]\n",
      "0.9746875\n"
     ]
    }
   ],
   "source": [
    "predict = model.predict(test_features)\n",
    "predicted_labels = np.argmax(predict, axis=1)\n",
    "matrix = confusion_matrix(test_labels, predicted_labels)\n",
    "accuracy = accuracy_score(test_labels, predicted_labels)\n",
    "print(matrix)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfefa23d",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "Baumdicker F, et al. (2022), Efficient ancestry and mutation simulation with msprime 1.0, *Genetics*, 220(3): iyab229. \n",
    "http://doi.org/10.1371/journal.pcbi.1004842\n",
    "\n",
    "Haller BC, Messer PW. (2023) SLiM 4: Multispecies eco-evolutionary modeling, *The American Naturalist*, 201(5): In press. https://doi.org/10.1086/723601\n",
    "\n",
    "Adrion JR, et al. (2020), A community-maintained standard library of population genetic models, *eLife* 9:e54967, https://doi.org/10.7554/eLife.54967\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
