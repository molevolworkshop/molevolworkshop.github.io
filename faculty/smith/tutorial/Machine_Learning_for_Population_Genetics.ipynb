{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c9f8d1c",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Author: Megan L Smith\n",
    "\n",
    "Date: April 27, 2023\n",
    "\n",
    "Purpose: Woodshole MOLE Course\n",
    "\n",
    "This jupyter notebook will illustrate an application of machine learning in population genetics. Specifically, we will simulate data under two simple demographic models using msprime. Then, we will format our simulated data as numpy matrices. We will use these matrices to train a convolutional neural network (CNN) using tensorflow and keras. Finally, we will generate an independent test dataset and test the classifier. This is a simple example that does not require machine learning, but it should illustrate the basic principles of using machine learning in python to analyze genomic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a5236c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-27 13:11:08.185578: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Import python packages\n",
    "# python version: 3.10.8\n",
    "import msprime # version 1.2.0\n",
    "import numpy as np # version 1.23.5\n",
    "from scipy.spatial.distance import euclidean # version 1.9.3\n",
    "import random\n",
    "\n",
    "# sklearn imports version 1.2.0\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import confusion_matrix, accuracy_score \n",
    "\n",
    "# tensorflow imports version 2.10.0\n",
    "from tensorflow.keras import layers, optimizers, models \n",
    "\n",
    "# keras imports version 2.10.0\n",
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e216fd78",
   "metadata": {},
   "source": [
    "# Simulating genetic data in msprime\n",
    "\n",
    "There are many simulators we could use to simulate data, and different problems require different simulators. For example, when we want to simulate selection, SLiM (Haller and Messer, 2022) may be a good choice. In this simple example, we will use msprime (Baumdicker et al., 2022). msprime integrates well into python pipelines, since it is a python package. It is also used in stdpopsim, a library for standardized population genetic simulations for many species (Adrion et al., 2020). We will keep it simple for the point of illustration and simulate data under two models: a divergence-only model and a divergence-with-gene-flow model. Our question is: do these two sister species have a history of gene flow?\n",
    "\n",
    "<div>\n",
    "<img src=\"Models-01.png\" width=\"500\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed5e4e1",
   "metadata": {},
   "source": [
    "## Specify demographic models\n",
    "\n",
    "Below, we specify our models. We could make these models much more complex. See the msprime documentation for more examples and possibilities: https://tskit.dev/msprime/docs/stable/demography.html. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54407fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our models in msprime\n",
    "\n",
    "def divergence(tdiv, ne_anc, ne_1, ne_2):  \n",
    "    \"\"\"This function defines a divergence-only model. \n",
    "        It takes as input several parameters:\n",
    "        tdiv (divergence time in generations)\n",
    "        ne_anc (the effective population size of the ancestral population)\n",
    "        ne_1 (the effective population size of population 1)\n",
    "        ne_2 (the effective population size of population 2)\"\"\"\n",
    "\n",
    "     # set up msprime model\n",
    "    demography = msprime.Demography()\n",
    "    demography.add_population(name=\"A\", initial_size = ne_1) # population 1\n",
    "    demography.add_population(name=\"B\", initial_size = ne_2) # population 2\n",
    "    demography.add_population(name=\"C\", initial_size = ne_anc) # ancestral population\n",
    "    demography.add_population_split(time=tdiv, derived=[\"A\", \"B\"], ancestral=\"C\") # divergence\n",
    "    return(demography)\n",
    "\n",
    "def geneflow(tdiv, migrate, ne_anc, ne_1, ne_2): # UPDATED\n",
    "    \"\"\"This function defines a geneflow model. \n",
    "        It takes as input several parameters:\n",
    "        tdiv (divergence time in generations)\n",
    "        migrate (the rate of migration between populations)\n",
    "        ne_anc (the effective population size of the ancestral population)\n",
    "        ne_1 (the effective population size of population 1)\n",
    "        ne_2 (the effective population size of population 2)\"\"\"\n",
    "\n",
    "     # set up msprime model\n",
    "    demography = msprime.Demography()\n",
    "    demography.add_population(name=\"A\", initial_size = ne_1) # population 1\n",
    "    demography.add_population(name=\"B\", initial_size = ne_2) # population 2\n",
    "    demography.add_population(name=\"C\", initial_size = ne_anc) # ancestral population\n",
    "    demography.set_symmetric_migration_rate(populations=[\"A\", \"B\"], rate=migrate) # set migration rate\n",
    "    demography.add_population_split(time=tdiv, derived=[\"A\", \"B\"], ancestral=\"C\") # divergence (migration stops)\n",
    "    return(demography)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f39d2c",
   "metadata": {},
   "source": [
    "## Specify priors and other values needed for simulations\n",
    "\n",
    "We will specify priors for parameters to use when generating training data. We also need to define a mutation rate. We could also draw this value from a prior distribution, but for the sake of simplicity, we will set Î¼ to a fixed value here. For this example (primarily for the sake of time) we assume there is no recombination within loci. Additionally, we need to specify the length of loci to simulate, the number of loci to simulate per replicate, the number of replicates to simulate per model, the number of SNPs to keep, and the number of individuals to sample per population. For this particular architecture, we assume equal numbers of samples from each population, but this is easily relaxed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7125612",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdiv_prior=[50000, 500000] # prior on divergence time\n",
    "ne_prior=[10000, 100000] # prior on ne\n",
    "migrate_prior=[1e-6,1e-4] # prior on migration rate\n",
    "mu = 1e-7 # mutation rate\n",
    "seq_len = 10000 # sequence length per fragment\n",
    "fragments = 20 # number of loci to simulate per replicate\n",
    "replicates = 1000 # nubmer of replicates to simulate per model\n",
    "sample_size = 10 # number of individuals to sample per extant population\n",
    "SNPs = 5000 # number of SNPs to keep per replicate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a3e4d2",
   "metadata": {},
   "source": [
    "## Utility function to reformat genotype matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad6eaf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_genotype_matrix(genotype_matrix, SNPs, sample_size):\n",
    "    \"\"\"This function will truncate the matrix to the number of specified SNPs \n",
    "    (or add -1s for padding if the matrix is too small),\n",
    "    It will also sort the matrix by similarity, which can help with training.\n",
    "    It will reformat the matrix to have two channels, one per population. \"\"\"\n",
    "    if genotype_matrix.shape[1] >= SNPs:\n",
    "        genotype_matrix = genotype_matrix[:,0:SNPs]\n",
    "    else:\n",
    "        new_columns = np.full((genotype_matrix.shape[0], SNPs - genotype_matrix.shape[1]), -1)\n",
    "        genotype_matrix = np.hstack((genotype_matrix, new_columns))\n",
    "\n",
    "    # reshape the array\n",
    "    reshaped = genotype_matrix.reshape(sample_size*2, SNPs, 2)\n",
    "    channel1 = genotype_matrix[:sample_size*2, :]\n",
    "    channel2 = genotype_matrix[sample_size*2:, :]\n",
    "\n",
    "    # sort the channels\n",
    "    ref_row = channel1[0]\n",
    "    distances=[euclidean(ref_row, row) for row in channel1]\n",
    "    sorted_indices = np.argsort(distances)\n",
    "    channel1_sorted = channel1[sorted_indices]\n",
    "    ref_row = channel2[0]\n",
    "    distances=[euclidean(ref_row, row) for row in channel2]\n",
    "    sorted_indices = np.argsort(distances)\n",
    "    channel2_sorted = channel2[sorted_indices]\n",
    "\n",
    "    reshaped = np.stack([channel1_sorted, channel2_sorted], axis=-1)\n",
    "    return(reshaped)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e51ec36",
   "metadata": {},
   "source": [
    "## Simulate data\n",
    "\n",
    "Now, we are ready to simulate data under our models. First, simulate data under the divergence model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "609c6756",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_data(tdiv_prior, ne_prior, sample_size, seq_len, mu, SNPs, replicates):\n",
    "\n",
    "    # lists for storing matrices, responses\n",
    "    all_matrices = []\n",
    "    all_responses = []\n",
    "\n",
    "    \n",
    "    for model in ['divergence', 'geneflow']:\n",
    "        \n",
    "        for i in range(replicates):\n",
    "\n",
    "            # draw parameters from priors\n",
    "            this_tdiv = random.randint(tdiv_prior[0], tdiv_prior[1])\n",
    "            this_ne_anc = random.randint(ne_prior[0], ne_prior[1])\n",
    "            this_ne_1 = random.randint(ne_prior[0], ne_prior[1])\n",
    "            this_ne_2 = random.randint(ne_prior[0], ne_prior[1])\n",
    "            if model == \"geneflow\":\n",
    "                this_migrate = np.random.uniform(low=migrate_prior[0], high=migrate_prior[1])\n",
    "               \n",
    "            # get our demography (using the function defined above)  \n",
    "            if model == \"divergence\":\n",
    "                demography = divergence(tdiv=this_tdiv, ne_anc=this_ne_anc, ne_1=this_ne_1, ne_2=this_ne_2)\n",
    "            elif model == \"geneflow\":\n",
    "                demography = geneflow(tdiv=this_tdiv, migrate=this_migrate, ne_anc=this_ne_anc, \n",
    "                                    ne_1=this_ne_1, ne_2=this_ne_2)\n",
    "            # simulate j fragments \n",
    "            for j in range(fragments):\n",
    "\n",
    "                # simulate tree sequences\n",
    "                ts = msprime.sim_ancestry(samples={\"A\": sample_size, \"B\": sample_size}, \n",
    "                                  demography = demography, sequence_length=seq_len)\n",
    "    \n",
    "                # simulate mutations\n",
    "                mts = msprime.sim_mutations(ts, rate=mu)\n",
    "\n",
    "        \n",
    "                # create np.array\n",
    "                genotype_matrix_fragment = mts.genotype_matrix().transpose()\n",
    "                if j == 0:\n",
    "                    genotype_matrix = genotype_matrix_fragment\n",
    "                else:\n",
    "                    genotype_matrix=np.concatenate((genotype_matrix, genotype_matrix_fragment), axis=1)\n",
    "\n",
    "            # after we have simulated all fragments, modify the genotype matrix a utility function defined above (modify_gentoype_matrix)\n",
    "            reshaped_genotype_matrix = modify_genotype_matrix(genotype_matrix, SNPs, sample_size)\n",
    "    \n",
    "            # get responses\n",
    "            if model == 'divergence':\n",
    "                response = 0\n",
    "            elif model == 'geneflow':\n",
    "                response = 1\n",
    "    \n",
    "            # append to lists\n",
    "            all_matrices.append(reshaped_genotype_matrix)\n",
    "            all_responses.append(response)\n",
    "    \n",
    "    # convert lists to numpy arrays\n",
    "    all_matrices = np.stack(all_matrices, axis=0)\n",
    "    all_responses = np.stack(all_responses)\n",
    "    \n",
    "    \n",
    "    return(all_matrices, all_responses)\n",
    "\n",
    "\n",
    "simulated_matrices, simulated_responses = simulate_data(tdiv_prior, ne_prior, sample_size, seq_len, mu, SNPs, replicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1badee2c",
   "metadata": {},
   "source": [
    "# Train a Machine Learning classifier!\n",
    "\n",
    "Now, we have data we can use to train our classifier. We need to build and train our classifier!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc8b494",
   "metadata": {},
   "source": [
    "## Build the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43760eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 20, 5000, 2)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 18, 5000, 10)      70        \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 6, 5000, 10)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 300000)            0         \n",
      "                                                                 \n",
      " 100 (Dense)                 (None, 20)                6000020   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 20)                0         \n",
      "                                                                 \n",
      " final (Dense)               (None, 2)                 42        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,000,132\n",
      "Trainable params: 6,000,132\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-27 13:16:54.736764: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# create our layers\n",
    "conv1 = layers.Conv2D(10, (3, 1), activation='relu', input_shape=(sample_size*2, SNPs, 2))\n",
    "pool1 = layers.MaxPooling2D((3, 1))\n",
    "flatten = layers.Flatten(name=\"flatten\")\n",
    "dense100 = layers.Dense(20, activation='relu', name=\"100\")\n",
    "dense5 = layers.Dense(5, activation='relu', name=\"5\")\n",
    "dropout = layers.Dropout(rate=0.1)\n",
    "densefinal = layers.Dense(2, activation='softmax', name=\"final\")\n",
    "\n",
    "# specify input\n",
    "x = layers.Input(shape=(sample_size*2, SNPs, 2))\n",
    "\n",
    "# build our model\n",
    "x1 = conv1(x)\n",
    "x1 = pool1(x1)\n",
    "x1 = flatten(x1)\n",
    "x1 = dense100(x1)\n",
    "x1 = dropout(x1)\n",
    "outputs = densefinal(x1)\n",
    "\n",
    "# compile the model\n",
    "model = models.Model(inputs=x, outputs=outputs)    \n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=0.00001), loss=\"categorical_crossentropy\", metrics='accuracy')\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f74d8b",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fd5826b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60/60 [==============================] - 12s 184ms/step - loss: 0.5626 - accuracy: 0.7283 - val_loss: 0.4709 - val_accuracy: 0.8000\n",
      "Epoch 2/10\n",
      "60/60 [==============================] - 11s 184ms/step - loss: 0.3735 - accuracy: 0.8642 - val_loss: 0.4407 - val_accuracy: 0.7937\n",
      "Epoch 3/10\n",
      "60/60 [==============================] - 13s 211ms/step - loss: 0.2652 - accuracy: 0.9208 - val_loss: 0.3870 - val_accuracy: 0.8125\n",
      "Epoch 4/10\n",
      "60/60 [==============================] - 13s 215ms/step - loss: 0.1964 - accuracy: 0.9708 - val_loss: 0.3649 - val_accuracy: 0.8062\n",
      "Epoch 5/10\n",
      "60/60 [==============================] - 13s 217ms/step - loss: 0.1356 - accuracy: 0.9900 - val_loss: 0.3525 - val_accuracy: 0.8188\n",
      "Epoch 6/10\n",
      "60/60 [==============================] - 13s 223ms/step - loss: 0.1018 - accuracy: 0.9967 - val_loss: 0.3475 - val_accuracy: 0.8562\n",
      "Epoch 7/10\n",
      "60/60 [==============================] - 13s 218ms/step - loss: 0.0773 - accuracy: 0.9983 - val_loss: 0.3315 - val_accuracy: 0.8250\n",
      "Epoch 8/10\n",
      "60/60 [==============================] - 13s 212ms/step - loss: 0.0601 - accuracy: 1.0000 - val_loss: 0.3259 - val_accuracy: 0.8375\n",
      "Epoch 9/10\n",
      "60/60 [==============================] - 13s 211ms/step - loss: 0.0498 - accuracy: 1.0000 - val_loss: 0.3296 - val_accuracy: 0.8625\n",
      "Epoch 10/10\n",
      "60/60 [==============================] - 13s 215ms/step - loss: 0.0433 - accuracy: 1.0000 - val_loss: 0.3187 - val_accuracy: 0.8562\n"
     ]
    }
   ],
   "source": [
    "# divide data into training, test, and validation\n",
    "\n",
    "train_features, test_val_features, train_labels, test_val_labels = train_test_split(simulated_matrices, simulated_responses, test_size = 0.4)\n",
    "test_features, val_features, test_labels, val_labels = train_test_split(test_val_features, test_val_labels, test_size = 0.2)\n",
    "\n",
    "# convert labels to categorical \n",
    "train_labels_cat = to_categorical(train_labels, num_classes=2)\n",
    "test_labels_cat = to_categorical(test_labels, num_classes=2)\n",
    "val_labels_cat = to_categorical(val_labels, num_classes=2)\n",
    "\n",
    "# fit our model\n",
    "history = model.fit(train_features, train_labels_cat, epochs=10, \n",
    "                        validation_data=(val_features, val_labels_cat), batch_size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f6d3b9",
   "metadata": {},
   "source": [
    "## Test the model\n",
    "\n",
    "It is important to test the model on an indpendent dataset. We did not use our test data for validation (which would be important if we adjusted model parameters to improve performance), or for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aff15bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 3s 132ms/step\n",
      "[[267  46]\n",
      " [ 26 301]]\n",
      "0.8875\n"
     ]
    }
   ],
   "source": [
    "predict = model.predict(test_features)\n",
    "predicted_labels = np.argmax(predict, axis=1)\n",
    "matrix = confusion_matrix(test_labels, predicted_labels)\n",
    "accuracy = accuracy_score(test_labels, predicted_labels)\n",
    "print(matrix)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfefa23d",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "Baumdicker F, et al. (2022), Efficient ancestry and mutation simulation with msprime 1.0, *Genetics*, 220(3): iyab229. \n",
    "http://doi.org/10.1371/journal.pcbi.1004842\n",
    "\n",
    "Haller BC, Messer PW. (2023) SLiM 4: Multispecies eco-evolutionary modeling, *The American Naturalist*, 201(5): In press. https://doi.org/10.1086/723601\n",
    "\n",
    "Adrion JR, et al. (2020), A community-maintained standard library of population genetic models, *eLife* 9:e54967, https://doi.org/10.7554/eLife.54967\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
